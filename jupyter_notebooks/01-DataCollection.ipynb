{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and prepare it for further processing.\n",
        "  - Clean data\n",
        "  - Split data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "*   Kaggle JSON file - the authentication token. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: inputs/cherry_leaves_dataset/cherry-leaves\n",
        "\n",
        "\n",
        "## Comments | Insights | Conclusions\n",
        "\n",
        "* These steps are necessary to fetch the data, clean it, and divide it into subsets for the purposes of machine learning. \n",
        "\n",
        "* The next step will be Data Visualization to understand the data and discover patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r /workspace/Portfolio_5_Cherry_Leaves_Mildew/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('/workspace/Portfolio_5_Cherry_Leaves_Mildew')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# install kaggle package\n",
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the cell below **to change kaggle configuration directory to current working directory and permission of kaggle authentication json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if the DestinationFolder exists, removes it if it does, creates a new one, downloads the dataset, and then unzips it. It ensures that any existing data is removed before downloading the new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Define your Kaggle dataset path and destination folder\n",
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/cherry_leaves_dataset\"\n",
        "\n",
        "# Check if the data folder already exists\n",
        "if os.path.exists(DestinationFolder):\n",
        "    print(\"Data folder already exists. Removing existing data...\")\n",
        "    # Remove existing data folder and its contents\n",
        "    shutil.rmtree(DestinationFolder)\n",
        "\n",
        "# Create the destination folder\n",
        "os.makedirs(DestinationFolder)\n",
        "\n",
        "# Download the dataset\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n",
        "\n",
        "# Unzip the downloaded file and delete the zip file\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check and remove non images files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  # remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_non_image_file(my_data_dir='inputs/cherry_leaves_dataset/cherry-leaves')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split train validation test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "  \n",
        "  if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "    print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum 1.0\")\n",
        "    return\n",
        "\n",
        "  # gets classes labels\n",
        "  labels = os.listdir(my_data_dir) # it should get only the folder name\n",
        "  if 'test' in labels:\n",
        "    pass\n",
        "  else: \n",
        "    # create train, test folders with classess labels sub-folder\n",
        "    for folder in ['train','validation','test']:\n",
        "      for label in labels:\n",
        "        os.makedirs(name=my_data_dir+ '/' + folder + '/' + label)\n",
        "\n",
        "    for label in labels:\n",
        "\n",
        "      files = os.listdir(my_data_dir + '/' + label)\n",
        "      random.shuffle(files)\n",
        "\n",
        "      train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "      validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "      count = 1\n",
        "      for file_name in files:\n",
        "        if count <= train_set_files_qty:\n",
        "          # move given file to train set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                      my_data_dir + '/train/' + label + '/' + file_name)\n",
        "          \n",
        "\n",
        "        elif count <= (train_set_files_qty + validation_set_files_qty ):\n",
        "          # move given file to validation set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                      my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "        else:\n",
        "          # move given file to test set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                  my_data_dir + '/test/' +label + '/'+ file_name)\n",
        "          \n",
        "        count += 1\n",
        "\n",
        "      os.rmdir(my_data_dir + '/' + label)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conventionally,\n",
        "\n",
        "* The training set is divided into 70% ratio of data.\n",
        "* The validation set is divided into 10% ratio of data.\n",
        "* The test set is divided into 20% ratio of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(my_data_dir = f\"inputs/cherry_leaves_dataset/cherry-leaves\",\n",
        "                        train_set_ratio = 0.70,\n",
        "                        validation_set_ratio=0.10,\n",
        "                        test_set_ratio=0.20\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data has been downloaded from Kaggle, underwent cleaning, and has now been organized into separate train, test, and validation folders, ready for further development and processing."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
