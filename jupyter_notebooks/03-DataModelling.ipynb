{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Modelling and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Answer business requirement 2: \n",
    "    * The client seeks to predict whether a cherry leaf is healthy or infected with powdery mildew.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/train\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/test\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/validation\n",
    "* image shape embeddings\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Images distribution plot in train, validation, and test set\n",
    "* Image augmentation\n",
    "* Class indices to change prediction inference in labels\n",
    "* Machine learning model creation and training\n",
    "* Save model\n",
    "* Learning curve plot for model performance\n",
    "* Model evaluation on pickle file\n",
    "* Prediction on the random image file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Additional Comments:\n",
    "\n",
    "N/A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Data Directory and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/Portfolio_5_Cherry_Leaves_Mildew')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set input directories (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set train, validation and test paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/workspace/Portfolio_5_Cherry_Leaves_Mildew/inputs/cherry_leaves_dataset/cherry-leaves'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version = 'v1'\n",
    "base_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'  # Make sure to set your base directory\n",
    "file_path = os.path.join(base_dir, 'outputs', version)\n",
    "\n",
    "# Function to automatically increment version\n",
    "def increment_version(ver):\n",
    "    base, num = ver[:-1], int(ver[-1])  # Assumes version format is vX where X is a digit\n",
    "    return f\"{base}{num + 1}\"\n",
    "\n",
    "# Check if 'outputs' directory exists, if not, create it\n",
    "if 'outputs' not in os.listdir(base_dir):\n",
    "    os.makedirs(os.path.join(base_dir, 'outputs'))\n",
    "\n",
    "# Check if the specific version exists\n",
    "if version in os.listdir(os.path.join(base_dir, 'outputs')):\n",
    "    print('Old version is already available. Creating a new version...')\n",
    "    # Increment the version until a new, unused version is found\n",
    "    while version in os.listdir(os.path.join(base_dir, 'outputs')):\n",
    "        version = increment_version(version)\n",
    "    # Create a new version directory\n",
    "    new_file_path = os.path.join(base_dir, 'outputs', version)\n",
    "    os.makedirs(new_file_path)\n",
    "    print(f\"New version created: {version}\")\n",
    "else:\n",
    "    # If the version doesn't exist, create the specified version directory\n",
    "    os.makedirs(file_path)\n",
    "    print(f\"Version {version} created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set label names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_dir)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import saved image shape embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of images per set and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_freq = pd.DataFrame([])\n",
    "for folder in ['train', 'test', 'validation']:\n",
    "    for label in labels:\n",
    "        df_freq = pd.concat(\n",
    "            [df_freq,\n",
    "             pd.Series(data={'Set': folder,\n",
    "                             'Label': label,\n",
    "                             'Count': int(len(os.listdir(base_dir + '/' + folder + '/' + label)))}\n",
    "                       )],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(base_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Distribution - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have separate lists for \"Set,\" \"Label,\" and \"Count\"\n",
    "sets = [\"train\", \"train\", \"test\", \"test\", \"validation\", \"validation\"]\n",
    "labels = [\"healthy\", \"powdery_mildew\", \"healthy\", \"powdery_mildew\", \"healthy\", \"powdery_mildew\"]\n",
    "counts = [1472, 1472, 422, 422, 210, 210]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_freq = pd.DataFrame({'Set': sets, 'Label': labels, 'Count': counts})\n",
    "\n",
    "fig = px.bar(df_freq, \n",
    "             x='Set', \n",
    "             y='Count', \n",
    "             color='Label',\n",
    "             title='Cherry Leaves Dataset',\n",
    "             text_auto=True\n",
    "            )\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800, \n",
    "    height=500, \n",
    "    )\n",
    "fig.show()\n",
    "fig.write_image(f'outputs/v1/bar_chart.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have separate lists for \"Set\" and \"Count\"\n",
    "sets = [\"train\", \"test\", \"validation\"]\n",
    "counts = [1472, 422, 210]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_sets = pd.DataFrame({'Set': sets, 'Count': counts})\n",
    "\n",
    "# Create the pie chart\n",
    "fig = px.pie(df_sets, \n",
    "             values='Count', \n",
    "             names='Set', \n",
    "             title='Dataset Split',\n",
    "             color='Set',\n",
    "             color_discrete_map={'train': 'blue', 'test': 'green', 'validation': 'orange'}  # Optionally specify color for each set\n",
    "            )\n",
    "\n",
    "# Show the chart\n",
    "fig.show()\n",
    "fig.write_image(f'outputs/v1/pie_chart.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Images from Train, Test, and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Note that validation data should not be augmented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intiatize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images(image_gen, num_images=20):\n",
    "    \"\"\"\n",
    "    Plots a grid of `num_images` from an image generator.\n",
    "    \n",
    "    :param image_gen: The image generator object.\n",
    "    :param num_images: The number of images to plot.\n",
    "    \"\"\"\n",
    "    images, _ = next(image_gen)  # Get a batch of images and labels\n",
    "    \n",
    "    # Calculate grid size and create a new figure\n",
    "    n_cols = 5  # Number of columns in the grid\n",
    "    n_rows = num_images // n_cols + (num_images % n_cols > 0)  # Calculate required rows\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])  # Images are already rescaled by the generator\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot augmented train images\n",
    "plot_augmented_images(train_generator, num_images=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment test image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_images(directory_iterator, num_images=10):\n",
    "    \"\"\"\n",
    "    Plots a specified number of test images from a DirectoryIterator.\n",
    "    \n",
    "    :param directory_iterator: A DirectoryIterator yielding batches of images and labels.\n",
    "    :param num_images: The number of test images to plot.\n",
    "    \"\"\"\n",
    "    # Get a batch of images and labels using next()\n",
    "    images, _ = next(directory_iterator)\n",
    "    \n",
    "    # Determine the grid size for plotting\n",
    "    n_cols = min(num_images, 5)  # Adjust the number of columns as needed, maxing out at 5\n",
    "    n_rows = num_images // n_cols + (num_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):  # Ensure we do not exceed the batch size or num_images\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_generator is your DirectoryIterator instance\n",
    "plot_test_images(test_generator, num_images=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment train image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_train_images(generator, num_images=8):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given generator.\n",
    "    \n",
    "    :param generator: The generator yielding batches of images and labels.\n",
    "    :param num_images: The number of images to plot from a single batch.\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)  # Get a batch of images and labels\n",
    "\n",
    "    n_cols = min(num_images, 4)  # Number of columns in the plot\n",
    "    n_rows = num_images // n_cols + int(num_images % n_cols != 0)  # Calculate required number of rows\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_images(validation_generator, num_images=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment validation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_images(generator, num_images=8):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given generator.\n",
    "    \n",
    "    :param generator: The generator yielding batches of images and labels.\n",
    "    :param num_images: The number of images to plot from a single batch.\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)  # Get a batch of images and labels\n",
    "\n",
    "    n_cols = min(num_images, 4)  # Number of columns in the plot\n",
    "    n_rows = num_images // n_cols + int(num_images % n_cols != 0)  # Calculate required number of rows\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_images(validation_generator, num_images=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Class Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {'healthy': 0, 'powdery_mildew': 1} \n",
    "\n",
    "# Save the class indices to a file using joblib or any other suitable method\n",
    "joblib.dump(class_indices, f'{file_path}/class_indices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced model and hyperparameter tuning using GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Initialize the model with the correct input shape\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)),  # Updated input shape\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a callback function in Keras that monitors the model's accuracy and stops training once the accuracy reaches 97% (or any other threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class AccuracyThresholdCallback(Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to stop training when a specified accuracy threshold is reached.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold, min_epochs):\n",
    "        super(AccuracyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.min_epochs = min_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check if the accuracy threshold has been reached\n",
    "        if epoch >= self.min_epochs - 1:  # epochs are zero-indexed\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') >= self.threshold:\n",
    "                print(f\"\\nEpoch {epoch+1}: Reached {self.threshold * 100}% accuracy. Stopping training.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Instantiate the callback with your desired threshold\n",
    "accuracy_threshold_callback = AccuracyThresholdCallback(threshold=0.99, min_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit model for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DetailedHistory(Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        # Log training metrics more frequently (e.g., every 10 batches)\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Batch {batch}: Loss = {logs['loss']}, Accuracy = {logs['accuracy']}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Log validation metrics at the end of each epoch\n",
    "        print(f\"Epoch {epoch}: Val Loss = {logs['val_loss']}, Val Accuracy = {logs['val_accuracy']}\")\n",
    "\n",
    "detailed_history = DetailedHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=len(train_generator.classes) // 20,\n",
    "    validation_data=validation_generator,  # Make sure this is provided\n",
    "    validation_steps=len(validation_generator.classes) // 20,\n",
    "    callbacks=[detailed_history, accuracy_threshold_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Plot only if 'val_loss' is present\n",
    "if 'val_loss' in loss.columns:\n",
    "    loss[['loss', 'val_loss']].plot(style='.-')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.savefig(f'outputs/v1/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "if 'val_accuracy' in loss.columns:\n",
    "    loss[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.savefig(f'outputs/v1/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save evaluation pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation ,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve shows the relationship between the TPR and FPR for various classification thresholds. The AUC is a metric that measures the overall performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred = model.predict(test_generator)\n",
    "\n",
    "# Calculate FPR, TPR, and classification thresholds\n",
    "fpr, tpr, thresholds = roc_curve(test_generator.classes, pred)\n",
    "\n",
    "# Calculate area under the curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2,\n",
    "         label=f'ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=2,\n",
    "         linestyle='--', label='Random Guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'/workspace/Portfolio_5_Cherry_Leaves_Mildew/outputs/v1/roc_curve.png', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def grayscale_with_color_histograms(my_image):\n",
    "    # Load the image\n",
    "    image = cv2.imread(my_image)\n",
    "    \n",
    "    # Check if the image is loaded successfully\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error loading image. Please check the file path.\")\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute color histograms for each RGB channel\n",
    "    b_hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    g_hist = cv2.calcHist([image], [1], None, [256], [0, 256])\n",
    "    r_hist = cv2.calcHist([image], [2], None, [256], [0, 256])\n",
    "    \n",
    "    # Plot the color histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(b_hist, color='blue', label='Blue')\n",
    "    plt.plot(g_hist, color='green', label='Green')\n",
    "    plt.plot(r_hist, color='red', label='Red')\n",
    "    plt.title('Color Histograms')\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the grayscale image\n",
    "    return grayscale_image\n",
    "\n",
    "# Example usage\n",
    "my_image = 'static/images/powdery_mildew_3.jpg'\n",
    "result_image = grayscale_with_color_histograms(my_image)\n",
    "plt.imshow(result_image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HSV (Hue, Saturation, Value) color space in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def convert_to_hsv(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image is loaded successfully\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error loading image. Please check the file path.\")\n",
    "    \n",
    "    # Convert BGR to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    return hsv_image\n",
    "\n",
    "# Example usage\n",
    "image_path = '/workspace/Portfolio_5_Cherry_Leaves_Mildew/static/images/powdery_mildew_2.jpg'\n",
    "hsv_image = convert_to_hsv(image_path)\n",
    "\n",
    "# Display the original and HSV images\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(hsv_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('HSV Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a Random Image File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load a random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Select a random label from the 'labels' list\n",
    "random_label = random.choice(labels)\n",
    "\n",
    "# Construct the path for the chosen label\n",
    "label_dir = os.path.join(test_dir, random_label)\n",
    "\n",
    "# Get a list of all files in the chosen label directory\n",
    "files_in_label_dir = os.listdir(label_dir)\n",
    "\n",
    "# Select a random file from the list of files\n",
    "random_file = random.choice(files_in_label_dir)\n",
    "\n",
    "# Construct the full path for the randomly selected image\n",
    "image_path = os.path.join(label_dir, random_file)\n",
    "\n",
    "# Load the image\n",
    "pil_image = image.load_img(image_path, target_size=image_shape, color_mode='rgb')\n",
    "\n",
    "print(f'Randomly selected label: {random_label}')\n",
    "print(f'Image path: {image_path}')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(pil_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert image to array and prepare for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0,0]\n",
    "\n",
    "target_map = {v: k for k, v in train_generator.class_indices.items()}\n",
    "pred_class =  target_map[pred_proba > 0.5]  \n",
    "\n",
    "if pred_class == target_map[0]: pred_proba = 1 - pred_proba\n",
    "\n",
    "print(pred_proba)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Effective Performance**: The model showcases impressive performance, even with a relatively small dataset, highlighting its efficiency in learning from limited data.\n",
    "\n",
    "- **Consistent Learning**: Analysis of loss and accuracy curves reveals a stable and consistent training behavior, with no signs of overfitting or underfitting, indicating a well-tuned model.\n",
    "\n",
    "- **Accurate Predictions**: Demonstrates a strong capability to accurately predict the class of new, unseen images, confirming the model's generalization ability.\n",
    "\n",
    "- **Data Augmentation Impact**: The application of data augmentation techniques significantly contributed to the model's robustness, allowing it to handle a variety of image orientations and scales.\n",
    "\n",
    "- **Real-World Applicability**: The model's reliability in classifying cherry leaf diseases underlines its potential for real-world agricultural applications, offering valuable support for early disease detection and management.\n",
    "\n",
    "- **Future Improvement Avenues**: While current results are promising, exploring more complex architectures, deeper networks, and larger datasets could further enhance model performance and reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
