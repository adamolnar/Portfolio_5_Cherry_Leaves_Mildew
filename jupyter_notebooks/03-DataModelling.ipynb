{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Modelling and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Answer business requirement 2: \n",
    "    * The client seeks to predict whether a cherry leaf is healthy or infected with powdery mildew.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/train\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/test\n",
    "* inputs/cherry_leaves_dataset/cherry-leaves/validation\n",
    "* image shape embeddings\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Images distribution plot in train, validation, and test set\n",
    "* Image augmentation\n",
    "* Class indices to change prediction inference in labels\n",
    "* Machine learning model creation and training\n",
    "* Save model\n",
    "* Learning curve plot for model performance\n",
    "* Model evaluation on pickle file\n",
    "* Prediction on the random image file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Additional Comments:\n",
    "\n",
    "N/A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Data Directory and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/Portfolio_5_Cherry_Leaves_Mildew')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Portfolio_5_Cherry_Leaves_Mildew'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set input directories (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set train, validation and test paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/workspace/Portfolio_5_Cherry_Leaves_Mildew/inputs/cherry_leaves_dataset/cherry-leaves'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old version is already available. Creating a new version...\n",
      "New version created: v3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "version = 'v1'\n",
    "base_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'  # Make sure to set your base directory\n",
    "file_path = os.path.join(base_dir, 'outputs', version)\n",
    "\n",
    "# Function to automatically increment version\n",
    "def increment_version(ver):\n",
    "    base, num = ver[:-1], int(ver[-1])  # Assumes version format is vX where X is a digit\n",
    "    return f\"{base}{num + 1}\"\n",
    "\n",
    "# Check if 'outputs' directory exists, if not, create it\n",
    "if 'outputs' not in os.listdir(base_dir):\n",
    "    os.makedirs(os.path.join(base_dir, 'outputs'))\n",
    "\n",
    "# Check if the specific version exists\n",
    "if version in os.listdir(os.path.join(base_dir, 'outputs')):\n",
    "    print('Old version is already available. Creating a new version...')\n",
    "    # Increment the version until a new, unused version is found\n",
    "    while version in os.listdir(os.path.join(base_dir, 'outputs')):\n",
    "        version = increment_version(version)\n",
    "    # Create a new version directory\n",
    "    new_file_path = os.path.join(base_dir, 'outputs', version)\n",
    "    os.makedirs(new_file_path)\n",
    "    print(f\"New version created: {version}\")\n",
    "else:\n",
    "    # If the version doesn't exist, create the specified version directory\n",
    "    os.makedirs(file_path)\n",
    "    print(f\"Version {version} created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set label names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for the images are ['healthy', 'powdery_mildew']\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir(train_dir)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import saved image shape embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of images per set and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train - healthy: 1472 images\n",
      "* train - powdery_mildew: 1472 images\n",
      "* test - healthy: 422 images\n",
      "* test - powdery_mildew: 422 images\n",
      "* validation - healthy: 210 images\n",
      "* validation - powdery_mildew: 210 images\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_freq = pd.DataFrame([])\n",
    "for folder in ['train', 'test', 'validation']:\n",
    "    for label in labels:\n",
    "        df_freq = pd.concat(\n",
    "            [df_freq,\n",
    "             pd.Series(data={'Set': folder,\n",
    "                             'Label': label,\n",
    "                             'Count': int(len(os.listdir(base_dir + '/' + folder + '/' + label)))}\n",
    "                       )],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(base_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "0            train\n",
      "1          healthy\n",
      "2             1472\n",
      "3            train\n",
      "4   powdery_mildew\n",
      "5             1472\n",
      "6             test\n",
      "7          healthy\n",
      "8              422\n",
      "9             test\n",
      "10  powdery_mildew\n",
      "11             422\n",
      "12      validation\n",
      "13         healthy\n",
      "14             210\n",
      "15      validation\n",
      "16  powdery_mildew\n",
      "17             210\n"
     ]
    }
   ],
   "source": [
    "print(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 22\u001b[0m\n\u001b[1;32m     10\u001b[0m df_freq \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet\u001b[39m\u001b[38;5;124m'\u001b[39m: sets, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: labels, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m: counts})\n\u001b[1;32m     12\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mbar(df_freq, \n\u001b[1;32m     13\u001b[0m              x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m              width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, \n\u001b[1;32m     20\u001b[0m              height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/bar_chart.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/plotly/basedatatypes.py:3841\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3781\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3782\u001b[0m \u001b[38;5;124;03mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[1;32m   3783\u001b[0m \u001b[38;5;124;03mobject\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3837\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3838\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3839\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/plotly/io/_kaleido.py:266\u001b[0m, in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mCannot infer image type from output path '{file}'.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 )\n\u001b[1;32m    261\u001b[0m             )\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# ---------\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/plotly/io/_kaleido.py:132\u001b[0m, in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Raise informative error message if Kaleido is not installed\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mImage export using the \"kaleido\" engine requires the kaleido package,\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mwhich can be installed using pip:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    $ pip install -U kaleido\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Validate figure\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# ---------------\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     fig_dict \u001b[38;5;241m=\u001b[39m validate_coerce_fig_to_dict(fig, validate)\n",
      "\u001b[0;31mValueError\u001b[0m: \nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have separate lists for \"Set,\" \"Label,\" and \"Count\"\n",
    "sets = [\"train\", \"train\", \"test\", \"test\", \"validation\", \"validation\"]\n",
    "labels = [\"healthy\", \"powdery_mildew\", \"healthy\", \"powdery_mildew\", \"healthy\", \"powdery_mildew\"]\n",
    "counts = [1472, 1472, 422, 422, 210, 210]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_freq = pd.DataFrame({'Set': sets, 'Label': labels, 'Count': counts})\n",
    "\n",
    "fig = px.bar(df_freq, \n",
    "             x='Label', \n",
    "             y='Count', \n",
    "             color='Set',\n",
    "             title='Label Distribution in Train, Test, and Validation Sets',\n",
    "             labels={'Count': 'Number of Images', 'Label': 'Label'},\n",
    "             category_orders={\"Set\": [\"train\", \"test\", \"validation\"]},\n",
    "             width=800, \n",
    "             height=400)\n",
    "\n",
    "fig.write_image(f'{file_path}/bar_chart.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "fig = px.bar(df_freq, x='Set', y='Label', color='Count',\n",
    "             title='Label Distribution in Train, Test, and Validation Sets',\n",
    "             labels={'Count': 'Number of Images', 'Label': 'Label'},\n",
    "             width=800, height=400,\n",
    "             color_discrete_sequence=['blue', 'green', 'red'])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Images from Train, Test, and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Note that validation data should not be augmented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intiatize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images(image_gen, num_images=20):\n",
    "    \"\"\"\n",
    "    Plots a grid of `num_images` from an image generator.\n",
    "    \n",
    "    :param image_gen: The image generator object.\n",
    "    :param num_images: The number of images to plot.\n",
    "    \"\"\"\n",
    "    images, _ = next(image_gen)  # Get a batch of images and labels\n",
    "    \n",
    "    # Calculate grid size and create a new figure\n",
    "    n_cols = 5  # Number of columns in the grid\n",
    "    n_rows = num_images // n_cols + (num_images % n_cols > 0)  # Calculate required rows\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])  # Images are already rescaled by the generator\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot augmented train images\n",
    "plot_augmented_images(train_generator, num_images=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment test image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_images(directory_iterator, num_images=10):\n",
    "    \"\"\"\n",
    "    Plots a specified number of test images from a DirectoryIterator.\n",
    "    \n",
    "    :param directory_iterator: A DirectoryIterator yielding batches of images and labels.\n",
    "    :param num_images: The number of test images to plot.\n",
    "    \"\"\"\n",
    "    # Get a batch of images and labels using next()\n",
    "    images, _ = next(directory_iterator)\n",
    "    \n",
    "    # Determine the grid size for plotting\n",
    "    n_cols = min(num_images, 5)  # Adjust the number of columns as needed, maxing out at 5\n",
    "    n_rows = num_images // n_cols + (num_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):  # Ensure we do not exceed the batch size or num_images\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_generator is your DirectoryIterator instance\n",
    "plot_test_images(test_generator, num_images=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment train image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_train_images(generator, num_images=8):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given generator.\n",
    "    \n",
    "    :param generator: The generator yielding batches of images and labels.\n",
    "    :param num_images: The number of images to plot from a single batch.\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)  # Get a batch of images and labels\n",
    "\n",
    "    n_cols = min(num_images, 4)  # Number of columns in the plot\n",
    "    n_rows = num_images // n_cols + int(num_images % n_cols != 0)  # Calculate required number of rows\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_images(validation_generator, num_images=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augment validation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_images(generator, num_images=8):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given generator.\n",
    "    \n",
    "    :param generator: The generator yielding batches of images and labels.\n",
    "    :param num_images: The number of images to plot from a single batch.\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)  # Get a batch of images and labels\n",
    "\n",
    "    n_cols = min(num_images, 4)  # Number of columns in the plot\n",
    "    n_rows = num_images // n_cols + int(num_images % n_cols != 0)  # Calculate required number of rows\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_images(validation_generator, num_images=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Class Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {'healthy': 0, 'powdery_mildew': 1} \n",
    "\n",
    "# Save the class indices to a file using joblib or any other suitable method\n",
    "joblib.dump(class_indices, f'{file_path}/class_indices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced model and hyperparameter tuning using GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Initialize the model with the correct input shape\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)),  # Updated input shape\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a callback function in Keras that monitors the model's accuracy and stops training once the accuracy reaches 97% (or any other threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class AccuracyThresholdCallback(Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to stop training when a specified accuracy threshold is reached.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold, min_epochs):\n",
    "        super(AccuracyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.min_epochs = min_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check if the accuracy threshold has been reached\n",
    "        if epoch >= self.min_epochs - 1:  # epochs are zero-indexed\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') >= self.threshold:\n",
    "                print(f\"\\nEpoch {epoch+1}: Reached {self.threshold * 100}% accuracy. Stopping training.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Instantiate the callback with your desired threshold\n",
    "accuracy_threshold_callback = AccuracyThresholdCallback(threshold=0.99, min_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit model for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DetailedHistory(Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        # Log training metrics more frequently (e.g., every 10 batches)\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Batch {batch}: Loss = {logs['loss']}, Accuracy = {logs['accuracy']}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Log validation metrics at the end of each epoch\n",
    "        print(f\"Epoch {epoch}: Val Loss = {logs['val_loss']}, Val Accuracy = {logs['val_accuracy']}\")\n",
    "\n",
    "detailed_history = DetailedHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=len(train_generator.classes) // 20,\n",
    "    validation_data=validation_generator,  # Make sure this is provided\n",
    "    validation_steps=len(validation_generator.classes) // 20,\n",
    "    callbacks=[detailed_history, accuracy_threshold_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Plot only if 'val_loss' is present\n",
    "if 'val_loss' in loss.columns:\n",
    "    loss[['loss', 'val_loss']].plot(style='.-')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.savefig(f'outputs/v1/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "if 'val_accuracy' in loss.columns:\n",
    "    loss[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.savefig(f'outputs/v1/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save evaluation pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation ,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a Random Image File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load a random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Select a random label from the 'labels' list\n",
    "random_label = random.choice(labels)\n",
    "\n",
    "# Construct the path for the chosen label\n",
    "label_dir = os.path.join(test_dir, random_label)\n",
    "\n",
    "# Get a list of all files in the chosen label directory\n",
    "files_in_label_dir = os.listdir(label_dir)\n",
    "\n",
    "# Select a random file from the list of files\n",
    "random_file = random.choice(files_in_label_dir)\n",
    "\n",
    "# Construct the full path for the randomly selected image\n",
    "image_path = os.path.join(label_dir, random_file)\n",
    "\n",
    "# Load the image\n",
    "pil_image = image.load_img(image_path, target_size=image_shape, color_mode='rgb')\n",
    "\n",
    "print(f'Randomly selected label: {random_label}')\n",
    "print(f'Image path: {image_path}')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(pil_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert image to array and prepare for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0,0]\n",
    "\n",
    "target_map = {v: k for k, v in train_generator.class_indices.items()}\n",
    "pred_class =  target_map[pred_proba > 0.5]  \n",
    "\n",
    "if pred_class == target_map[0]: pred_proba = 1 - pred_proba\n",
    "\n",
    "print(pred_proba)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Effective Performance**: The model showcases impressive performance, even with a relatively small dataset, highlighting its efficiency in learning from limited data.\n",
    "\n",
    "- **Consistent Learning**: Analysis of loss and accuracy curves reveals a stable and consistent training behavior, with no signs of overfitting or underfitting, indicating a well-tuned model.\n",
    "\n",
    "- **Accurate Predictions**: Demonstrates a strong capability to accurately predict the class of new, unseen images, confirming the model's generalization ability.\n",
    "\n",
    "- **Data Augmentation Impact**: The application of data augmentation techniques significantly contributed to the model's robustness, allowing it to handle a variety of image orientations and scales.\n",
    "\n",
    "- **Real-World Applicability**: The model's reliability in classifying cherry leaf diseases underlines its potential for real-world agricultural applications, offering valuable support for early disease detection and management.\n",
    "\n",
    "- **Future Improvement Avenues**: While current results are promising, exploring more complex architectures, deeper networks, and larger datasets could further enhance model performance and reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
